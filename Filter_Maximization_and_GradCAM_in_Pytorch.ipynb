{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Filter Maximization in Pytorch"
      ],
      "metadata": {
        "id": "aiwfpo2V7Oou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Reference:\n",
        "\n",
        "* https://github.com/anaramirli/visualizing-cnn-features\n",
        "\n",
        "* https://github.com/fg91/visualizing-cnn-feature-maps/blob/master/filter_visualizer.ipynb"
      ],
      "metadata": {
        "id": "K4gYYNSZBhng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import gc\n",
        "import cv2\n",
        "import math\n",
        "import warnings\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import PIL\n",
        "import imutils\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.python.client import device_lib\n",
        "from zipfile import ZipFile\n",
        "from IPython import display\n",
        "from google.colab.patches import cv2_imshow\n",
        "from imutils.contours import sort_contours\n",
        "\n",
        "print(\"Device Specifications:\")\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNjJGE-cA9Xv",
        "outputId": "19cc1adc-49e5-4b21-a9dd-0d3f8218da62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Specifications:\n",
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 7872263534344546596\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 13825277952\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 11743418767575673948\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6z_jULjBL5j",
        "outputId": "bea1bc9e-dd12-4985-b84c-03fdb4d20488"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we use a project from a long time ago, which is Pytorch's OCR Notebook."
      ],
      "metadata": {
        "id": "W4dyusKW_uin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # We calculate this formula for padding.\n",
        "    # NOTES: Filter_size = kernel_size\n",
        "    # In this case, we use same padding, the formula is: [(filter_size  - 1) / 2] ( Same Padding--> input size = output size).\n",
        "\n",
        "    # Formula of feature map size: [(input_size - filter_size + 2(padding) / stride) + 1]\n",
        "    # Output after conv1: [(28 - 3 + 2 (1) / 1) + 1] = 28\n",
        "    # Output after MaxPool1 = 28 / 2 = 14\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, padding = 1, bias = True), \n",
        "        nn.ReLU(), \n",
        "        nn.MaxPool2d(2,2))\n",
        "\n",
        "    # To attain same padding: we use features of \n",
        "    # Padding: [(3 - 1) / 2] = 1\n",
        "    # Output after conv2: [(14 - 3 + 2 (1) / 1) + 1] = 14\n",
        "    # Output after MaxPool2: 14 / 2 = 7\n",
        "    self.conv2 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1, bias = True), \n",
        "      nn.ReLU(), \n",
        "      nn.MaxPool2d(2,2)\n",
        "    )\n",
        "\n",
        "    self.conv3 = nn.Sequential(\n",
        "      nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 1, bias = True), \n",
        "      nn.ReLU(), \n",
        "      nn.MaxPool2d(2,2)\n",
        "    )\n",
        "\n",
        "    # Flatten the layers.\n",
        "    # 32 = number of filters\n",
        "    # 7 = size of max pool 2 feature map output.\n",
        "    self.fc1 = nn.Sequential(\n",
        "      nn.Flatten(), \n",
        "      nn.Linear(128*3*3,64), \n",
        "      nn.ReLU(), \n",
        "      nn.Linear(64,32),\n",
        "      nn.ReLU()\n",
        "    )\n",
        "    self.fc2 = nn.Sequential(\n",
        "      nn.Linear(32,16), \n",
        "      nn.ReLU(), \n",
        "      nn.Linear(16,8), \n",
        "      nn.ReLU()\n",
        "    )\n",
        "    self.fc3 = nn.Sequential(nn.Linear(8,10))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "mnist_model = MNISTModel().to(device)\n",
        "mnist_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GKJHET4AqV7",
        "outputId": "97f6de90-8e64-498e-b931-592bc2273306"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTModel(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1152, out_features=64, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (4): ReLU()\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (fc3): Sequential(\n",
              "    (0): Linear(in_features=8, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pYnh51603zSt"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "cross_entropy_loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# For our gradient descent algorthim or Optimizer\n",
        "# We use Stochastic Gradient Descent (SGD) with a learning rate of 0.001\n",
        "# We set the momentum to be 0.9\n",
        "optimizer = optim.SGD(mnist_model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model, optimizer, filename = \"model.pth.tar\"):\n",
        "  print(\"Loading model...\")\n",
        "  checkpoint = torch.load(filename)\n",
        "  model.load_state_dict(checkpoint['model_state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "  print(\"Finished loading model!\")\n",
        "\n",
        "  return model, optimizer\n",
        "\n",
        "directory_path = \"./drive/MyDrive/Models\"\n",
        "mnist_model, optimizer = load_model(mnist_model, optimizer, f\"{directory_path}/ocr_mnist_model.pth.tar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZoPvxCC95Hd",
        "outputId": "ba151f62-9804-4bc1-d711-643fe7e11fb4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "Finished loading model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_transform = transforms.Compose([\n",
        "    transforms.RandomAffine(degrees = 10, translate = (0.1, 0.1), shear = 2),\n",
        "    transforms.RandomRotation(50),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, ), (0.5, )) # Scale to -1 to 1\n",
        "])\n",
        "\n",
        "mnist_validation_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, ), (0.5, )),\n",
        "])\n",
        "\n",
        "mnist_trainset = torchvision.datasets.MNIST('emnist', \n",
        "                                      train = True, \n",
        "                                      download = True,\n",
        "                                      transform = mnist_train_transform)\n",
        "\n",
        "mnist_valset = torchvision.datasets.MNIST('emnist', \n",
        "                                      train = False, \n",
        "                                      download = True,\n",
        "                                      transform = mnist_validation_transform)\n",
        "\n",
        "print(mnist_trainset.data.shape)\n",
        "print(mnist_valset.data.shape)\n",
        "\n",
        "print(mnist_trainset.targets.shape)\n",
        "print(mnist_valset.targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s_eobCXl1ft",
        "outputId": "72d6b6d7-c62f-4fcf-c110-1af3e03d4512"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to emnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 77652100.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting emnist/MNIST/raw/train-images-idx3-ubyte.gz to emnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to emnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28105729.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting emnist/MNIST/raw/train-labels-idx1-ubyte.gz to emnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to emnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 27828757.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting emnist/MNIST/raw/t10k-images-idx3-ubyte.gz to emnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to emnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 16623498.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting emnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to emnist/MNIST/raw\n",
            "\n",
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n",
            "torch.Size([60000])\n",
            "torch.Size([10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "mnist_train_loader = torch.utils.data.DataLoader(\n",
        "    mnist_trainset, \n",
        "    batch_size = batch_size, \n",
        "    shuffle = True,\n",
        ")\n",
        "\n",
        "mnist_validation_loader = torch.utils.data.DataLoader(\n",
        "    mnist_valset, \n",
        "    batch_size = batch_size, \n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "uj7YFo8xmuGp"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "rR4kCCE-HBjc",
        "outputId": "17592257-9a2b-4f77-9899-adda6c09e6da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-648a2bab0435>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Maximization."
      ],
      "metadata": {
        "id": "bGUc8tQF-qIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's suppose we'd like to visualize the architecture from conv3 layer. We can replace the last layer of ."
      ],
      "metadata": {
        "id": "AfslPtHaJi-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_layers_from_model(model):\n",
        "  # Get all the model layers, except Sequential Layer, \n",
        "  # since we'd like to iterate the layers one by one.\n",
        "  model_layers = list(model.modules())[1:]\n",
        "  flattened_model_layers = []\n",
        "\n",
        "  # Filter layers, as we don't want to process sequential layers.\n",
        "  for index, module in enumerate(model_layers):\n",
        "    if type(module) != torch.nn.modules.container.Sequential:\n",
        "      flattened_model_layers.append(module)\n",
        "\n",
        "  return flattened_model_layers\n",
        "\n",
        "MAX_CONV_LAYERS = 7\n",
        "flattened_model = flatten_layers_from_model(mnist_model)[:MAX_CONV_LAYERS]\n",
        "flattened_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4yotNLxQhRn",
        "outputId": "6c407cb0-2f70-4538-e3c3-13b1e1d5a74f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
              " ReLU(),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
              " ReLU(),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VisualizeConvFilterModel(nn.Module):\n",
        "  def __init__(self, model, last_layer_num_features, num_classes):\n",
        "    super(VisualizeConvFilterModel, self).__init__()\n",
        "    self.model = nn.Sequential(*model)\n",
        "    self.last_layer = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(last_layer_num_features, num_classes),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    x = self.last_layer(x)\n",
        "    return x\n",
        "\n",
        "visualize_conv_filter_model = VisualizeConvFilterModel(\n",
        "    flattened_model, 6272, 10\n",
        ").to(device)\n",
        "visualize_conv_filter_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAVxzuXWF8Rt",
        "outputId": "f5f28741-16f4-4222-94b8-34e35a791912"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisualizeConvFilterModel(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  )\n",
              "  (last_layer): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=6272, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name_grad_exception = \"weight\"\n",
        "\n",
        "for layer_name, param in visualize_conv_filter_model.named_parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "print(visualize_conv_filter_model.model[-1])\n",
        "visualize_conv_filter_model.model[-1].requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgQYX3-BfOIK",
        "outputId": "ec56dde5-e37e-41e7-e343-28a12d7713aa"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy_loss_function = nn.CrossEntropyLoss()\n",
        "activation_maximization_optimizer = optim.Adam(\n",
        "  visualize_conv_filter_model.parameters(), lr = 0.001\n",
        ")\n",
        "activation_maximization_optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5vqeD4aMm90",
        "outputId": "fd296902-cb24-451f-bf11-f47f374f403b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicHook():\n",
        "  \"\"\"\n",
        "  Get All of Layers Outputs, mainly for Visualization.\n",
        "  \"\"\"\n",
        "  def __init__(self, layer_name, layer, filter_numbers_to_visualize):\n",
        "    self.layer_name = layer_name\n",
        "    self.layer = layer\n",
        "    self.filter_numbers_to_visualize = filter_numbers_to_visualize\n",
        "    self.latest_output = None\n",
        "\n",
        "    layer.register_forward_hook(self.forward_hook_fn)\n",
        "    layer.register_backward_hook(self.backward_hook_fn)\n",
        "\n",
        "  def forward_hook_fn(self, layer, input, output):\n",
        "    self.latest_output = output\n",
        "    self.latest_output.requires_grad = True\n",
        "\n",
        "  def backward_hook_fn(self, layer, input, output):\n",
        "    self.latest_output = output\n",
        "    self.latest_output.requires_grad = True\n",
        "\n",
        "  # def visualize_output(self):\n",
        "  #   hstacked_output = torch.hstack(list(self.latest_output))\n",
        "  #   hstacked_output = hstacked_output.unsqueeze(1)\n",
        "\n",
        "  #   plt.title(self.layer_name)\n",
        "  #   plt.tight_layout()\n",
        "  #   plt.show()\n",
        "\n",
        "  # def convert_output_to_gif(self):\n",
        "  #   gif_filename = f\"{self.layer_name}.gif\"\n",
        "  #   output_frames = []\n",
        "  #   for frame in self.outputs:\n",
        "  #     hstacked_output = torch.hstack(list(frame))\n",
        "  #     hstacked_output = hstacked_output.unsqueeze(1)\n",
        "  #     grid_of_outputs_per_frame = torchvision.utils.make_grid(hstacked_output)\n",
        "  #     grid_of_outputs_per_frame = grid_of_outputs_per_frame.detach().cpu().numpy()\n",
        "  #     grid_of_outputs_per_frame = np.transpose(grid_of_outputs_per_frame, (1, 2, 0))\n",
        "  #     output_frames.append(grid_of_outputs_per_frame)\n",
        "\n",
        "  #   convert_frames_to_gif(output_frames, gif_name = gif_filename)\n",
        "\n",
        "  def close(self):\n",
        "    self.hook.remove()"
      ],
      "metadata": {
        "id": "z_jRrK3F7hp1"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_layer_name_for_filter_maximization, selected_layer_for_filter_maximization = list(\n",
        "    visualize_conv_filter_model.named_modules()\n",
        ")[8]\n",
        "\n",
        "hook = BasicHook(\n",
        "    selected_layer_name_for_filter_maximization,\n",
        "    selected_layer_for_filter_maximization,\n",
        "    [10, 20, 30]\n",
        ")\n",
        "\n",
        "print(selected_layer_for_filter_maximization)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEGx_YpvYPH3",
        "outputId": "294c578a-faec-4004-9851-20459f8299f1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(0, n_epochs):\n",
        "  total_loss = 0\n",
        "  for train_iteration, batch in enumerate(mnist_train_loader):\n",
        "    images_in_batch, labels_in_batch = batch\n",
        "    images_in_batch = images_in_batch.to(device)\n",
        "    labels_in_batch = labels_in_batch.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs_in_batch = visualize_conv_filter_model(\n",
        "        images_in_batch,\n",
        "    )\n",
        "\n",
        "    loss = cross_entropy_loss_function(outputs_in_batch, labels_in_batch)\n",
        "    total_loss += loss.item()\n",
        "    # outputs_in_batch.backward(labels_in_batch, retain_graph = True)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if train_iteration % 10 == 0:\n",
        "      print(f\"Current Epoch: {epoch}, iteration = {train_iteration}, with current loss: {loss.item()}\")\n",
        "      loss_log.append(loss.item())\n",
        "      iterations.append(train_iteration)\n",
        "  \n",
        "  save_model(mnist_model, optimizer, filename = f\"{directory_path}/ocr_mnist_model.pth.tar\")"
      ],
      "metadata": {
        "id": "y4QhAhZwC1tD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4b76b36a-edcd-43ff-8009-7f8d86cd64f9"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-6e417441e0e1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_in_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# outputs_in_batch.backward(labels_in_batch, retain_graph = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss_func' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grad_CAM"
      ],
      "metadata": {
        "id": "GUn6PZBi_T8b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kiW0F8pO_V0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}